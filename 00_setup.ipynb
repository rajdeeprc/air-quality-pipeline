{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c36149b5-5e86-411b-91cc-6ee7653fa925",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83C\uDF0D Air Quality Intelligence Pipeline\n",
    "## Setup & Configuration Notebook\n",
    "\n",
    "This notebook:\n",
    "- Creates the project database and Delta table directories\n",
    "- Defines all shared configuration variables\n",
    "- Validates the environment is ready for ingestion\n",
    "\n",
    "**Run this notebook FIRST before any other notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e4547e-7bde-484c-9398-88a16d2b0b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration variables loaded successfully.\n   Database   : air_quality_db\n   API Version: v3\n   API Key    : SET ✅\n   Cities     : 20 cities configured\n   Pollutants : ['pm25', 'pm10', 'no2', 'o3', 'co', 'so2']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PROJECT CONFIGURATION\n",
    "# Using Managed Tables — no explicit DBFS paths needed\n",
    "# ============================================================\n",
    "\n",
    "DATABASE_NAME = \"air_quality_db\"\n",
    "\n",
    "BRONZE_TABLE     = f\"{DATABASE_NAME}.bronze_raw_measurements\"\n",
    "SILVER_TABLE     = f\"{DATABASE_NAME}.silver_clean_measurements\"\n",
    "GOLD_TABLE_CITY  = f\"{DATABASE_NAME}.gold_city_rankings\"\n",
    "GOLD_TABLE_TREND = f\"{DATABASE_NAME}.gold_pollutant_trends\"\n",
    "GOLD_TABLE_AQI   = f\"{DATABASE_NAME}.gold_aqi_summary\"\n",
    "\n",
    "# ✅ Updated to OpenAQ v3\n",
    "API_BASE_URL = \"https://api.openaq.org/v3\"\n",
    "OPENAQ_API_KEY = \"6702146761c7bbc4554416a63c3856c80bd69d9faae0770cfe573214c0d6ea69\"   # ← paste your key here\n",
    "\n",
    "TARGET_CITIES = [\n",
    "    \"Delhi\", \"Mumbai\", \"Beijing\", \"Shanghai\", \"Lahore\",\n",
    "    \"Dhaka\", \"Karachi\", \"Lima\", \"Jakarta\", \"Bangkok\",\n",
    "    \"London\", \"Paris\", \"New York\", \"Los Angeles\", \"Tokyo\",\n",
    "    \"Seoul\", \"Mexico City\", \"Cairo\", \"Lagos\", \"Nairobi\"\n",
    "]\n",
    "\n",
    "TARGET_POLLUTANTS = [\"pm25\", \"pm10\", \"no2\", \"o3\", \"co\", \"so2\"]\n",
    "\n",
    "AQI_CATEGORIES = {\n",
    "    \"Good\":                  (0.0,   12.0),\n",
    "    \"Moderate\":              (12.1,  35.4),\n",
    "    \"Unhealthy (Sensitive)\": (35.5,  55.4),\n",
    "    \"Unhealthy\":             (55.5,  150.4),\n",
    "    \"Very Unhealthy\":        (150.5, 250.4),\n",
    "    \"Hazardous\":             (250.5, 9999.0)\n",
    "}\n",
    "\n",
    "print(\"✅ Configuration variables loaded successfully.\")\n",
    "print(f\"   Database   : {DATABASE_NAME}\")\n",
    "print(f\"   API Version: v3\")\n",
    "print(f\"   API Key    : {'SET ✅' if OPENAQ_API_KEY != 'PASTE_YOUR_API_KEY_HERE' else 'NOT SET ❌ — paste your key above'}\")\n",
    "print(f\"   Cities     : {len(TARGET_CITIES)} cities configured\")\n",
    "print(f\"   Pollutants : {TARGET_POLLUTANTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f244f8b3-af97-4e7c-898d-90cf31b4e304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database 'air_quality_db' is ready.\n   (Detected column name: 'databaseName')\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CREATE DATABASE\n",
    "# ============================================================\n",
    "\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {DATABASE_NAME}\")\n",
    "spark.sql(f\"USE {DATABASE_NAME}\")\n",
    "\n",
    "# Confirm creation — compatible with all Databricks runtime versions\n",
    "db_df = spark.sql(\"SHOW DATABASES\")\n",
    "\n",
    "# Dynamically detect the correct column name\n",
    "col_name = db_df.columns[0]  # Works regardless of runtime version\n",
    "databases = [row[col_name] for row in db_df.collect()]\n",
    "\n",
    "if DATABASE_NAME in databases:\n",
    "    print(f\"✅ Database '{DATABASE_NAME}' is ready.\")\n",
    "    print(f\"   (Detected column name: '{col_name}')\")\n",
    "else:\n",
    "    raise Exception(f\"❌ Database '{DATABASE_NAME}' was NOT created. Check permissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd9d6e9-c3f3-4208-93be-4c1370500543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bronze table ready : air_quality_db.bronze_raw_measurements\n✅ Silver table ready : air_quality_db.silver_clean_measurements\n✅ Gold table ready   : air_quality_db.gold_city_rankings\n✅ Gold table ready   : air_quality_db.gold_pollutant_trends\n✅ Gold table ready   : air_quality_db.gold_aqi_summary\n\n\uD83D\uDCE6 All 5 managed Delta tables scaffolded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CREATE MANAGED DELTA TABLES (empty scaffolds)\n",
    "# Databricks manages all storage locations automatically\n",
    "# ============================================================\n",
    "\n",
    "spark.sql(f\"USE {DATABASE_NAME}\")\n",
    "\n",
    "# Bronze — raw API response\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {BRONZE_TABLE} (\n",
    "        city            STRING,\n",
    "        country         STRING,\n",
    "        pollutant       STRING,\n",
    "        value           DOUBLE,\n",
    "        unit            STRING,\n",
    "        location_name   STRING,\n",
    "        latitude        DOUBLE,\n",
    "        longitude       DOUBLE,\n",
    "        measured_at     TIMESTAMP,\n",
    "        ingested_at     TIMESTAMP,\n",
    "        source_url      STRING,\n",
    "        raw_json        STRING\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "print(f\"✅ Bronze table ready : {BRONZE_TABLE}\")\n",
    "\n",
    "# Silver — cleaned and validated\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {SILVER_TABLE} (\n",
    "        city            STRING,\n",
    "        country         STRING,\n",
    "        pollutant       STRING,\n",
    "        value           DOUBLE,\n",
    "        unit            STRING,\n",
    "        location_name   STRING,\n",
    "        latitude        DOUBLE,\n",
    "        longitude       DOUBLE,\n",
    "        measured_at     TIMESTAMP,\n",
    "        ingested_at     TIMESTAMP,\n",
    "        aqi_category    STRING,\n",
    "        is_valid        BOOLEAN\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "print(f\"✅ Silver table ready : {SILVER_TABLE}\")\n",
    "\n",
    "# Gold — city rankings\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {GOLD_TABLE_CITY} (\n",
    "        city            STRING,\n",
    "        country         STRING,\n",
    "        pollutant       STRING,\n",
    "        avg_value       DOUBLE,\n",
    "        max_value       DOUBLE,\n",
    "        min_value       DOUBLE,\n",
    "        reading_count   LONG,\n",
    "        dominant_aqi    STRING,\n",
    "        last_updated    TIMESTAMP\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "print(f\"✅ Gold table ready   : {GOLD_TABLE_CITY}\")\n",
    "\n",
    "# Gold — pollutant trends\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {GOLD_TABLE_TREND} (\n",
    "        city            STRING,\n",
    "        pollutant       STRING,\n",
    "        reading_date    DATE,\n",
    "        avg_value       DOUBLE,\n",
    "        reading_count   LONG\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "print(f\"✅ Gold table ready   : {GOLD_TABLE_TREND}\")\n",
    "\n",
    "# Gold — AQI summary\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {GOLD_TABLE_AQI} (\n",
    "        city            STRING,\n",
    "        aqi_category    STRING,\n",
    "        reading_count   LONG,\n",
    "        percentage      DOUBLE,\n",
    "        last_updated    TIMESTAMP\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "print(f\"✅ Gold table ready   : {GOLD_TABLE_AQI}\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCE6 All 5 managed Delta tables scaffolded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e32b665e-ce46-4b8b-aefd-655fe4a2f835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAQ v3 API is reachable.\n   Status Code   : 200\n   Sample Params : ['pm10', 'pm25', 'o3', 'co', 'no2']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VALIDATE OPENAQ v3 API IS REACHABLE\n",
    "# ============================================================\n",
    "\n",
    "import requests\n",
    "\n",
    "def test_api_connection():\n",
    "    \"\"\"Make a lightweight test call to OpenAQ v3 API.\"\"\"\n",
    "    \n",
    "    # v3 requires API key in the header\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-API-Key\": OPENAQ_API_KEY\n",
    "    }\n",
    "\n",
    "    test_url = f\"{API_BASE_URL}/parameters?limit=5\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(test_url, headers=headers, timeout=15)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            param_names = [p[\"name\"] for p in data.get(\"results\", [])]\n",
    "            print(f\"✅ OpenAQ v3 API is reachable.\")\n",
    "            print(f\"   Status Code   : {response.status_code}\")\n",
    "            print(f\"   Sample Params : {param_names}\")\n",
    "            return True\n",
    "\n",
    "        elif response.status_code == 401:\n",
    "            print(\"❌ Unauthorized — Your API key is invalid or not yet active.\")\n",
    "            print(\"   Check your key at: https://explore.openaq.org\")\n",
    "            return False\n",
    "\n",
    "        elif response.status_code == 410:\n",
    "            print(\"❌ Still hitting v2 endpoint — check API_BASE_URL in Cell 2.\")\n",
    "            return False\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️  Unexpected status: {response.status_code}\")\n",
    "            print(f\"   Response: {response.text[:300]}\")\n",
    "            return False\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"❌ Connection Error — Restart the cluster and try again.\")\n",
    "        return False\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"❌ Timeout — API did not respond within 15 seconds.\")\n",
    "        return False\n",
    "\n",
    "api_ok = test_api_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06bc93f5-f414-483a-8788-b0a3350b9b94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark Version : 4.1.0\n✅ Delta Lake    : Write/Read/Delete test passed\n✅ Managed Tables: Accessible and operational\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VALIDATE SPARK & DELTA LAKE\n",
    "# ============================================================\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
    "\n",
    "# Check Spark version\n",
    "print(f\"✅ Spark Version : {spark.version}\")\n",
    "\n",
    "# Explicit schema for test row\n",
    "schema = StructType([\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"pollutant\", StringType(), True),\n",
    "    StructField(\"value\", DoubleType(), True),\n",
    "    StructField(\"unit\", StringType(), True),\n",
    "    StructField(\"location_name\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"measured_at\", TimestampType(), True),\n",
    "    StructField(\"ingested_at\", TimestampType(), True),\n",
    "    StructField(\"source_url\", StringType(), True),\n",
    "    StructField(\"raw_json\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Validate Delta works by writing a row to bronze and reading it back\n",
    "test_row = spark.createDataFrame([\n",
    "    Row(\n",
    "        city=\"TestCity\", country=\"TC\", pollutant=\"pm25\",\n",
    "        value=0.0, unit=\"µg/m³\", location_name=\"test\",\n",
    "        latitude=0.0, longitude=0.0,\n",
    "        measured_at=None, ingested_at=None,\n",
    "        source_url=\"test\", raw_json=\"{}\"\n",
    "    )\n",
    "], schema=schema)\n",
    "\n",
    "test_row.write.format(\"delta\").mode(\"append\").saveAsTable(BRONZE_TABLE)\n",
    "\n",
    "count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {BRONZE_TABLE}\").collect()[0][\"cnt\"]\n",
    "assert count >= 1, \"Delta write/read test failed\"\n",
    "\n",
    "# Clean up the test row\n",
    "spark.sql(f\"DELETE FROM {BRONZE_TABLE} WHERE city = 'TestCity'\")\n",
    "\n",
    "print(f\"✅ Delta Lake    : Write/Read/Delete test passed\")\n",
    "print(f\"✅ Managed Tables: Accessible and operational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "674d3712-57c0-41e7-aa14-9c899304169d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n  \uD83C\uDF0D AIR QUALITY PIPELINE — SETUP COMPLETE\n=======================================================\n  ✅ Database     : air_quality_db\n  ✅ Bronze Path  : dbfs:/user/air_quality_pipeline/bronze/raw_measurements\n  ✅ Silver Path  : dbfs:/user/air_quality_pipeline/silver/clean_measurements\n  ✅ Gold Paths   : 3 tables configured\n  ✅ API          : Reachable\n  ✅ Delta Lake   : Operational\n=======================================================\n\n▶️  Next Step: Open and run  01_bronze_ingestion.py\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SETUP SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(\"  \uD83C\uDF0D AIR QUALITY PIPELINE — SETUP COMPLETE\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"  ✅ Database     : {DATABASE_NAME}\")\n",
    "print(f\"  ✅ Bronze Path  : {BRONZE_PATH}\")\n",
    "print(f\"  ✅ Silver Path  : {SILVER_PATH}\")\n",
    "print(f\"  ✅ Gold Paths   : 3 tables configured\")\n",
    "print(f\"  ✅ API          : {'Reachable' if api_ok else 'UNREACHABLE - check network'}\")\n",
    "print(f\"  ✅ Delta Lake   : Operational\")\n",
    "print(\"=\" * 55)\n",
    "print(\"\\n▶️  Next Step: Open and run  01_bronze_ingestion.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "871c129c-7e24-48de-9118-febfc55546ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}